{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47da72a5",
   "metadata": {},
   "source": [
    "## Evaluation Summary & Critical Analysis\n",
    "\n",
    "The following table summarizes the performance of the model on the test set (``small_matrix.csv``) using different feature types and evaluation metrics. The metrics used for evaluation are Precision, Normalized Discounted Cumulative Gain (NDCG), and Mean Reciprocal Rank (MRR). The results are presented for the top-10, top-20, top-50, and top-100 recommendations. The evaluation was considered successful if the videos in the top-k recommendations had a watch ratio per user greater than 0.75.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| Feature Type                        | Metric    | Top-10 | Top-20 | Top-50 | Top-100 |\n",
    "| ----------------------------------- | --------- | ------ | ------ | ------ | ------- |\n",
    "| **Category**                        | Precision | 0.2243 | 0.1934 | 0.1596 | 0.1747  |\n",
    "|                                     | NDCG      | 0.5511 | 0.5742 | 0.5768 | 0.5849  |\n",
    "|                                     | MRR       | 0.4385 | 0.4447 | 0.4458 | 0.4458  |\n",
    "| **Caption**                         | Precision | 0.1462 | 0.1185 | 0.1811 | 0.1931  |\n",
    "|                                     | NDCG      | 0.4247 | 0.4534 | 0.5058 | 0.5525  |\n",
    "|                                     | MRR       | 0.2921 | 0.2999 | 0.3020 | 0.3020  |\n",
    "| **Multimodal (Category + Caption)** | Precision | 0.1748 | 0.1335 | 0.1409 | 0.1493  |\n",
    "|                                     | NDCG      | 0.4423 | 0.4626 | 0.4804 | 0.5167  |\n",
    "|                                     | MRR       | 0.2832 | 0.2891 | 0.2899 | 0.2899  |\n",
    "\n",
    "## Observations\n",
    "\n",
    "The evaluation was performed using three different feature types: Category, Caption, and a combination of both (Multimodal). The results indicate that the model performs best with the Category feature type in terms of Precision and NDCG, while the Caption feature type shows a lower performance across all metrics.\n",
    "\n",
    "Category features yield the highest Precision and NDCG scores across all top-k recommendations, indicating that they are more effective in ranking relevant items compared to Caption features. The MRR scores also reflect this trend, with Category features consistently outperforming Caption features.\n",
    "The Caption features, while showing some improvement in the top-50 and top-100 recommendations, do not perform as well as Category features in terms of Precision and NDCG. The Multimodal feature type, which combines both Category and Caption features, shows slightly better performance than captions but does not surpass the categories.\n",
    "\n",
    "\n",
    "### Critical Analysis\n",
    "1. **Feature Selection**: The choice of features significantly impacts the model's performance. The Category feature appears to be the most informative, while the Caption feature seems less effective. This suggests that the model may benefit from additional or alternative features that capture more relevant information.\n",
    "2. **Model Complexity**: The model's complexity may also play a role in its performance. A simpler model with fewer parameters may generalize better, while a more complex model may overfit the training data. Future work could explore different model architectures or regularization techniques to improve performance.\n",
    "3. **Evaluation Metrics**: The choice of evaluation metrics is crucial for understanding the model's performance. While Precision and NDCG provide insights into the ranking quality, MRR offers a different perspective on the model's ability to retrieve relevant items. A comprehensive evaluation should consider multiple metrics to capture different aspects of performance.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
